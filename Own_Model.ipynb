{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = 'top_model_weight.h5'\n",
    "# Save the checkpoint in the /model_weight folder\n",
    "filepath = 'model_weight/My_Model_Weight.hdf5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "test_data_dir = 'data/test'\n",
    "nb_train_samples = 1620\n",
    "nb_validation_samples = 370\n",
    "nb_test_samples = 88\n",
    "epochs = 5\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "#base_model.load_weights(weights_path)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3, activation='softmax'))\n",
    "top_model.save_weights('top_model_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier, in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base model\n",
    "# model.add(top_model)\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "\n",
    "# set the first 15 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "sgd = SGD(1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile( loss='categorical_crossentropy',\n",
    "               optimizer=sgd, \n",
    "               metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1620 images belonging to 3 classes.\n",
      "Found 370 images belonging to 3 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 3)                 6489347   \n",
      "=================================================================\n",
      "Total params: 21,204,035\n",
      "Trainable params: 13,568,771\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    #color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "valid_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    #color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('My_Model_Weight.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keep only a single checkpoint, the best over test accuracy.\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model's weights\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 4695s 29s/step - loss: 0.5970 - acc: 0.6426 - val_loss: 0.6869 - val_acc: 0.6081\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60811, saving model to model_weight/My_Model_Weight.hdf5\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 4618s 29s/step - loss: 0.5888 - acc: 0.6395 - val_loss: 0.6807 - val_acc: 0.6297\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.60811 to 0.62973, saving model to model_weight/My_Model_Weight.hdf5\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 4601s 28s/step - loss: 0.5743 - acc: 0.6407 - val_loss: 0.6317 - val_acc: 0.6378\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.62973 to 0.63784, saving model to model_weight/My_Model_Weight.hdf5\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 4573s 28s/step - loss: 0.5886 - acc: 0.6278 - val_loss: 0.6224 - val_acc: 0.6432\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.63784 to 0.64324, saving model to model_weight/My_Model_Weight.hdf5\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 4613s 28s/step - loss: 0.5887 - acc: 0.6117 - val_loss: 0.6048 - val_acc: 0.6405\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.64324\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 4679s 29s/step - loss: 0.5705 - acc: 0.6259 - val_loss: 0.5799 - val_acc: 0.6730\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.64324 to 0.67297, saving model to model_weight/My_Model_Weight.hdf5\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 4690s 29s/step - loss: 0.5739 - acc: 0.6296 - val_loss: 0.6240 - val_acc: 0.6189\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.67297\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 6856s 42s/step - loss: 0.5670 - acc: 0.6130 - val_loss: 0.5815 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.67297 to 0.70000, saving model to model_weight/My_Model_Weight.hdf5\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 4662s 29s/step - loss: 0.5625 - acc: 0.6272 - val_loss: 0.5681 - val_acc: 0.6622\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.70000\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 5009s 31s/step - loss: 0.5544 - acc: 0.6444 - val_loss: 0.6276 - val_acc: 0.6162\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.70000\n"
     ]
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    verbose=1,callbacks=[checkpoint])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('My_Model_Weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
